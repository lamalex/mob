package coauthors

import (
	"fmt"
	"regexp"
	"strings"
)

// ParseCoauthors receives string input directly from --with
// parses it and returns a map of alias => coauthor?
// for solo aliases coauthor will be an empty string.
func ParseCoauthors(coauthorsArg string) (CoauthorsMap, error) {
	l := newLexer(coauthorsArg)
	p := newParser(l)

	return p.parseCoauthors()
}

// CoauthorsMap is a mapping from --with supplied
// alias/author name. Alias will always be
// a non-empty string. Author may be an empty
// string for solo-aliases
type CoauthorsMap = map[Alias]Author

// Author is a coauthor Name <email> specified
// in --with and parsed out.
type Author = string

// Alias is a --with specified user alias
// or an autogenerated initialation of the
// name passed in. There is no guarantee
// that alias exists in git config.
type Alias = string

type parser struct {
	l         *lexer
	curToken  Token
	peekToken Token
}

func newParser(l *lexer) *parser {
	p := &parser{l: l}

	// Initialize cur and peek
	p.nextToken()
	p.nextToken()

	return p
}

func (p *parser) nextToken() {
	p.curToken = p.peekToken
	p.peekToken = p.l.NextToken()
}

func (p *parser) parseCoauthors() (CoauthorsMap, error) {
	coauthors := make(map[Alias]Author)

	for p.curToken.Type != tokEol {
		alias, author, err := p.parseCoauthor()

		if err == nil {
			coauthors[alias] = author
		} else {
			return nil, err
		}
		// If next token is a comma this will move
		// the parser cursor to it. If its not a comma
		// it should be an EOL and the next next token
		// will set curToken to EOL.
		p.expectPeek(tokComma)
		p.nextToken()
	}

	return coauthors, nil
}

func (p *parser) parseCoauthor() (Alias, Author, error) {
	switch p.curToken.Type {
	case tokAuthor:
		return p.parseAuthorStatement()
	case tokAlias:
		return p.parseAliasStatement(), "", nil
	default:
		return "", "", fmt.Errorf("%s was found unexpectedly in --with \"%s\"", string(p.curToken.Type), string(p.l.input))
	}
}

func (p *parser) parseAuthorStatement() (Alias, Author, error) {
	author := p.curToken.Literal

	// Name <> => n, Name <>
	if !p.expectPeek(tokAssign) {
		return generateInitialation(author), author, nil
	}

	// Name <> as ,
	if !p.expectPeek(tokAlias) {
		// this is an error condition
		return "", "", fmt.Errorf("coauthor parse error. `%s as` requires you to specify an alias", author)
	}

	return aliasEscape(p.curToken.Literal), author, nil
}

func (p *parser) parseAliasStatement() Alias {
	return aliasEscape(p.curToken.Literal)
}

func (p *parser) peekTokenIs(t TokenType) bool {
	return p.peekToken.Type == t
}

func (p *parser) expectPeek(t TokenType) bool {
	if p.peekTokenIs(t) {
		p.nextToken()
		return true
	}

	return false
}

func generateInitialation(author Author) Alias {
	authorWords := strings.Split(author, " ")

	alias := ""
	for _, word := range authorWords {
		if word == " " {
			continue
		} else if word[0] == '<' {
			return alias
		} else {
			alias = alias + strings.ToLower(string(word[0]))
		}
	}

	return alias
}

func aliasEscape(alias Alias) Alias {
	return strings.Replace(alias, " ", "-", -1)
}

type TokenType string
type Token struct {
	Type    TokenType
	Literal string
}

const (
	// Identifiers and literals
	tokAlias  = "ALIAS"  // bh, t swift
	tokAuthor = "AUTHOR" // Butthead <notbeavis@mtv.show>,
	// Tay Swift <>
	// Operators
	tokAssign = "as"

	// Delimiters
	tokComma = ","
	tokEol   = "EOL"
)

type lexer struct {
	input        []rune
	position     int
	readPosition int
	ch           rune
}

func newLexer(input string) *lexer {
	l := &lexer{input: []rune(input)}
	l.readChar()

	return l
}

func (l *lexer) readChar() {
	if l.readPosition >= len(l.input) {
		l.ch = 0
	} else {
		l.ch = l.input[l.readPosition]
	}
	l.position = l.readPosition
	l.readPosition++
}

func (l *lexer) NextToken() Token {
	var tok Token

	switch l.ch {
	case ',':
		tok = newToken(tokComma, l.ch)
	case 0:
		tok.Literal = ""
		tok.Type = tokEol
	default:
		return l.readIdentifier()
	}

	l.readChar()
	return tok
}

// read everything until " as " or "," (but "\," is ok)
func (l *lexer) readIdentifier() Token {
	var tok Token
	reading := true
	position := l.position
	for reading {
		for !(isSpace(l.ch) || isUnescapedComma(string(l.input), l.readPosition) || isEOL(l.ch)) {
			l.readChar()
		}

		// Consume delimiter unless EOL
		if !isEOL(l.ch) {
			l.readChar()
		}

		authorMatcher := regexp.MustCompile(`.+\s+<.*>`)
		asMatcher := regexp.MustCompile(tokAssign + `\s+`)

		if authorMatcher.MatchString(string(l.input[position:l.position])) {
			literal := strings.TrimSpace(string(l.input[position:l.position]))
			tok = Token{tokAuthor, literal}
			reading = false
		} else if len(l.input) > position+3 && asMatcher.MatchString(string(l.input[position:position+3])) {
			literal := strings.TrimSpace(string(l.input[position:l.position]))
			tok = Token{tokAssign, literal}
			reading = false
		} else if l.ch == ',' || l.ch == 0 {
			literal := strings.TrimSpace(string(l.input[position:l.position]))
			tok = Token{tokAlias, literal}
			reading = false
		}
	}

	return tok
}

func isSpace(ch rune) bool {
	return ch == ' ' || ch == '\t' || ch == '\n' || ch == '\r'
}

func isUnescapedComma(input string, position int) bool {
	return position < len(input) && input[position] == ',' && position > 0 && input[position-1] != '\\'
}

func isEOL(ch rune) bool {
	return ch == 0
}

func newToken(tokenType TokenType, ch rune) Token {
	return Token{Type: tokenType, Literal: string(ch)}
}
